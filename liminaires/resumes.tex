% Résumés (de 1700 caractères maximum, espaces compris) dans la
% langue principale (1re occurrence de l'environnement « abstract »)
% et, facultativement, dans la langue secondaire (2e occurrence de
% l'environnement « abstract »)
\begin{abstract}
Cette thèse se place dans le cadre des modèles d'apprentissage automatique de classification binaire. Le cas d'application est le scoring de risque de crédit. En particulier, les méthodes proposées ainsi que les approches existantes sont illustrées par des données réelles de Crédit Agricole Consumer Finance, acteur majeur en Europe du crédit à la consommation, à l'origine de cette thèse grâce à un financement CIFRE.

%, plus précisément dans un contexte de classification~: on cherche à prédire l'appartenance à une catégorie de chaque observation de variables aléatoires dites explicatives dans un corpus. On restreint la problématique à la classification binaire (deux catégories possibles) et on dispose de la vraie catégorie pour une partie de ce corpus : on parle alors d'apprentissage semi-supervisé. L'``apprentissage'' consiste à établir par calcul une fonction de lien entre ces observations et leur catégorie respective, de manière à pouvoir prédire cette catégorie pour de nouvelles observations. On limite la famille de fonctions possibles à une famille de modèles et la tâche du statisticien est alors de choisir le modèle qui prédit ``le mieux possible'', c'est-à-dire de minimiser la perte d'information inhérente au caractère stochastique de la relation entre variables explicatives et la catégorie à prédire.

%Le ratio risque/récompense désigne en finance la logique selon laquelle un investissement peu risqué ne pourra être que faiblement rentable tandis qu'un investissement risqué a un rendement plus élevé mais est exposé à une perte. Les établissements financiers spécialisés en crédit à la consommation transposent ce principe en deux heuristiques : premièrement, le taux d'intérêt des crédits est adapté en fonction des clients et des produits ; deuxièmement, les clients demandeurs sont sélectionnés selon leur solvabilité. Ce mécanisme d'acceptation/rejet de la clientèle est composé de plusieurs règles de décision dont un score, le modèle précédemment décrit correspondant, en termes ``métier'', à une notation liée aux caractéristiques socio-démographiques de clients passés témoignant de la probabilité de défaut d'un nouveau client. La construction de ce score, qu'on désigne généralement par \textit{Credit Scoring}, repose sur des techniques statistiques et des heuristiques industrielles dont certaines ont été examinées dans cette thèse.

%Après une première partie décrivant l'évolution et le contexte industriels actuels ainsi que la littérature académique associée à la classification supervisée, 
Premièrement, on s'intéresse 
%dans une deuxième partie 
à la problématique de
%une contribution importante de cette thèse : la 
``réintégration des refusés'' ou comment tirer partie des informations collectées sur les clients refusés non étiquetés.  Ce problème industriel est reformulé en un problème statistique rigoureux par l'interprétation de l'absence d'étiquettes comme une perte d'information.
% que l'on peut compenser par un ajout ``industriel'' (financer une partie des clients supposés mauvais) ou un ajout ``statistique'' (modéliser le mécanisme de génération des données manquantes).

Une autre pratique industrielle est la discrétisation des variables continues et le regroupement des modalités de variables catégorielles avant la modélisation 
%par régression logistique 
pour des raisons pratiques (interprétabilité) et théoriques (performance de prédiction). Pour ce faire, des heuristiques internes, manuelles et chronophages, sont utilisées.
%, qui sont manuelles et prennent donc beaucoup de temps au statisticien.
% puisque cela implique de chercher dans un espace de modèles très grand. 
Sa ré-interprétation comme un problème à variables latentes a permis de proposer une nouvelle approche de résolution, basée sur un réseau de neurone utilisé comme graphe de calcul, et qui permet d'obtenir des garanties statistiques.

%On verra ensuite en troisième partie l'apport de la méthode proposée dans cette thèse pour la discrétisation (resp.\ le regroupement de modalités) des variables quantitatives (resp.\ qualitatives) constitutives du score. La ré-interprétation comme un problème à variables manquantes a permis de proposer une nouvelle approche de résolution dont les résultats sont significatifs en termes de performance et de gain de temps pour le statisticien.

De plus, il est courant d'introduire également des interactions afin d'améliorer la performance prédictive des modèles.
%, comme la présence simultanée d'une catégorie de revenus et d'un emploi particulier. 
Cette pratique est également manuelle et chronophage, c'est pourquoi on propose un algorithme de Metropolis-Hastings garantissant de trouver les meilleures interactions et rendant le mécanisme de construction des scores quasi-automatique.

%Outre la discrétisation et le regroupement de modalités, il est courant en \textit{Credit Scoring} d'introduire également des interactions, c'est-à-dire de choisir des produits de variables prédictives plutôt qu'un effet additif, comme la présence simultanée d'une catégorie de revenus et d'un emploi particulier. Nous ajouterons en quatrième partie une résolution du problème de sélection de ces interactions à l'algorithme développé en troisième partie, rendant le mécanisme de construction des scores quasi-automatique.

Nous prendrons ensuite du recul pour constater que le système d'acceptation est rarement constitué d'un seul score mais plutôt d'un arbre de scores
%, ou d'un mélange d'experts dans la littérature statistique
, chacun relatif à un segment de population particulier. Cette structure découle du développement historique de l'entreprise et est donc certainement sous-optimale. Nous proposerons des pistes de réflexion pour optimiser le système d'acceptation dans son entièreté qui montre de bons résultats empiriques et représente une direction de recherche future.

Enfin, nous conclurons cette thèse en explicitant les enjeux et défis de la grande dimension (en termes de prédicteurs) dans la pratique du \textit{Credit Scoring} dans la mesure où l'industrie souhaite mesurer l'apport de l'utilisation de données massives et non structurées, encore inutilisées.
%L'ensemble des travaux est illustré par des données réelles de \gls{cacf}, établissement bancaire spécialiste du crédit à la consommation à l'origine de cette thèse CIFRE.

\medskip

\end{abstract}

\begin{abstract}
This manuscript deals with model-based statistical learning in the binary classification setting. As an application, credit scoring is widely examined with a special attention on its specificities. Proposed and existing approaches are illustrated on real data from Crédit Agricole Consumer Finance, a financial institute specialized in consumer loans which financed this PhD through a CIFRE funding.

First, we consider the so-called reject inference problem, which aims at taking advantage of rejected credit applicants for which no repayment performance can be observed (\textit{i.e.}\ unlabelled observations). This industrial problem led to a research one by reinterpreting unlabelled observations as an information loss.

Next, the discretization of continuous features or grouping of levels of categorical features, which are empirical and time-consuming for practitioners, are seen here as a latent variable problem. This results in a new cost-effective and automatic processing which involves a particular neural network architecture and gives precise statistical guarantees.

Third, interactions of covariates may be introduced in the problem in order to improve the performance. This task, up to now manually processed by practitioners and combinatorial, is performed here with a Metropolis-Hastings sampling procedure which finds the best interactions.

Finally, we look at the scoring system as a whole. It generally consists of a tree-like structure composed of many scorecards, which is often not optimized but rather imposed by the company’s culture and / or history. We propose some lines of approach to optimize it which lead to good empirical results and new research directions.

This manuscript is concluded by a discussion on how curses and blessings of dimensionality (in the number of features) might affect the practice of Credit Scoring, since the industry is pushing forward the use of high-dimensional unstructured data.

%This manuscript is centred on model-based statistical learning in a binary classification setting with a special attention to \textit{Credit Scoring} and its related constraints. In particular, proposed methods and comparisons with existing approaches are illustrated on real data from Crédit Agricole Consumer Finance, a financial institute specialized in consumer loans which financed this PhD through a CIFRE funding.
%: the membership of partially labelled observations of random variables
% (semi-supervised learning), called predictive features and forming a training set, 
% to one of two categories. 
%We restrict the problem to binary classification (only two possible categories) and we are provided with the true category for some observations in the training set: this setting corresponds to semi-supervised learning. 
%``Learning'' consists in calculating a link function between these features and the labels,
% of observations in the training set, such that it enables us to apply its prediction to new data. This function 
% which is searched in a restricted space of models.
 % and the practitioner subsequently chooses the model that predicts ``best'', \textit{i.e.}\ which minimizes an information loss criterion attached to the intrinsic stochasticity of the link between predictive features and the label to predict.

%The risk-reward is a well known finance paradigm: the higher the risk of an investment, the higher the expected reward. 
%When it comes to consumer loans, 
%two heuristics are usually employed: first, the interest rate of the loan depends on the client's risk of defaulting and second, 
%applicants get rejected depending on their estimated creditworthiness. This acceptance / rejection mechanism is composed of several business rules, among which 
%the score, \textit{i.e.}\ 
%the aforementioned model which predicts
%outputs a numeric value depending upon socio-demographic characteristics of past clients and their repayment behaviour which tends to reflect 
% the propensity of new clients to pay back. The construction of such scores relies on both statistical learning and \textit{ad hoc}, industrial recipes, which are partly tackled in this manuscript.

%The first chapter focuses on the industrial context of \textit{Credit Scoring} and its associated academic literature of supervised classification. In the second chapter
%First, we consider the so-called ``Reject Inference'' problem, which aims at taking into account information about previously rejected clients (for which no repayment performance was observed). This industrial problem leads to a rigorous statistical formulation by reinterpreting unlabelled observations as an information loss that can be compensated by an ``industrial'' addition (financing some of these supposedly bad applicants) or a ``statistical'' addition (the cost of modelling its missingness mechanism).

%Another industrial practice of \textit{Credit Scoring} is to discretize (resp.\ group) continuous features (resp.\ levels of categorical features) before performing logistic regression for practical (interpretability) and theoretical (performance) reasons. To do so, in-house heuristics are usually used, which are manual and subsequently take a lot of the practitioner's time since it involves searching through a huge model space. We reinterpret this practice as a latent variable problem and propose a new resolution, based on a particular neural network architecture which acts as a computational graph and enables us to give precise statistical guarantees. The results are satisfactory both in performance and in saving the practitioner's time, on benchmark and \textit{Credit Scoring} data.

%Moreover, interactions among covariates, \textit{e.g.}\ the simultaneous presence of a category of wages and a type of job, might be introduced in the logistic regression model for better performance. We build on what was proposed for discretization and grouping of factor levels to automatically search for the best interactions among covariates. This task was even more manual and combinatorial, and less formalized in the existing literature. Our proposal relies on a Metropolis-Hastings sampling procedure which is guaranteed to find the best interactions.

%Finally, we take a step back and look at the acceptance system as a whole: it is generally composed of many scorecards, in a tree-like structure which is often not optimized over but rather imposed by the company's culture and / or history. We propose some guidelines to optimize the whole scoring system which leads to good empirical results and future research directions.

%This manuscript is concluded by a discussion on how curse and blessing of dimensionality (in the number of features) might affect the practice of \textit{Credit Scoring}, since the industry is pushing forward to use high-dimensional unstructured data.

\medskip

\end{abstract}

\makeabstract