points_graph_temoins = array(rep(NA,10*3),dim=c(10,3))
for (k in 1:10) {
if (length(na.omit(unlist(list_tca_temoins_values[[k]]))) > 0) {
temp = t.test(na.omit(unlist(list_tca_temoins_values[[k]])))
points_graph_temoins[k,1] = temp$estimate
points_graph_temoins[k,2] = temp$conf.int[1]
points_graph_temoins[k,3] = temp$conf.int[2]
}
}
points_graph_temoins <- data.frame(points_graph_temoins)
colnames(points_graph_temoins) <- c("Mean","Low","High")
points_graph_temoins$Time <- 1:10*12/24 - 0.25
points_graph_temoins$Serum <- "Temoins"
points_graph <- rbind(points_graph_temoins,points_graph_traites)
ggplot(points_graph, aes(x=Time, y=Mean, colour=Serum)) +
geom_errorbar(aes(ymin=Low, ymax=High), width=.1) +
geom_line() +
geom_point() +
ylim(0,4) +
xlab("Jour(s) depuis envenimation") +
ylab("TCA ratio (%)")
ggsave(filename="courbe_tca_global.png", device="png")
list_tp_temoins_values = list()
list_tp_traites_values = list()
for (k in 1:10) {
temp_temoins = which(indices[1:42,,k],arr.ind = TRUE)
temp_traites = which(indices[43:84,,k],arr.ind = TRUE)
list_tp_temoins_values[[k]] = list()
list_tp_traites_values[[k]] = list()
if (nrow(temp_temoins)>0) {
for (i in 1:nrow(temp_temoins)) {
list_tp_temoins_values[[k]] = append(list_tp_temoins_values[[k]],base_tot[temp_temoins[i,"row"],ifelse(temp_temoins[i,"col"]==1,"TP.....H",paste0("TP.....H.",temp_temoins[i,"col"]-1))])
}
}
if (nrow(temp_traites)>0) {
for (i in 1:nrow(temp_traites)) {
list_tp_traites_values[[k]] = append(list_tp_traites_values[[k]],base_tot[temp_traites[i,"row"],ifelse(temp_traites[i,"col"]==1,"TP.....H",paste0("TP.....H.",temp_traites[i,"col"]-1))])
}
}
}
points_graph_traites = array(rep(NA,10*3),dim=c(10,3))
for (k in 1:10) {
if (length(na.omit(unlist(list_tp_traites_values[[k]]))) > 0) {
temp = t.test(na.omit(unlist(list_tp_traites_values[[k]])))
points_graph_traites[k,1] = temp$estimate
points_graph_traites[k,2] = temp$conf.int[1]
points_graph_traites[k,3] = temp$conf.int[2]
}
}
points_graph_traites <- data.frame(points_graph_traites)
colnames(points_graph_traites) <- c("Mean","Low","High")
points_graph_traites$Time <- 1:10*12/24 - 0.25
points_graph_traites$Serum <- "Traites"
points_graph_temoins = array(rep(NA,10*3),dim=c(10,3))
for (k in 1:10) {
if (length(na.omit(unlist(list_tp_temoins_values[[k]]))) > 0) {
temp = t.test(na.omit(unlist(list_tp_temoins_values[[k]])))
points_graph_temoins[k,1] = temp$estimate
points_graph_temoins[k,2] = temp$conf.int[1]
points_graph_temoins[k,3] = temp$conf.int[2]
}
}
points_graph_temoins <- data.frame(points_graph_temoins)
colnames(points_graph_temoins) <- c("Mean","Low","High")
points_graph_temoins$Time <- 1:10*12/24 - 0.25
points_graph_temoins$Serum <- "Temoins"
points_graph <- rbind(points_graph_temoins,points_graph_traites)
ggplot(points_graph, aes(x=Time, y=Mean, colour=Serum)) +
geom_errorbar(aes(ymin=Low, ymax=High), width=.1) +
ylim(0,110) +
geom_line() +
geom_point() +
xlab("Jour(s) depuis envenimation") +
ylab("TP (%)")
ggsave(filename="courbe_tp_global.png", device="png")
data <- carData::TitanicSurvival
?carData::TitanicSurvival
?rpart
??rpart
library(rpart)
?rpart
?rpart
library(glmdisc)
d=3
contr.ltfr = caret::contr.ltfr
generate_data <- function(k,n) {
set.seed(k)
x = matrix(runif(d*n), nrow = n, ncol = d)
cuts = seq(0,1,length.out= 4)
xd = apply(x,2, function(col) as.numeric(cut(col,cuts)))
theta = t(matrix(c(0,0,0,2,2,0,-2,-2,0),ncol=3,nrow=3))
log_odd = rowSums(t(sapply(seq_along(xd[,1]), function(row_id) sapply(seq_along(xd[row_id,]),
function(element) theta[xd[row_id,element],element]))))
y = rbinom(n,1,1/(1+exp(-log_odd)))
return(list(x=x,y=y,log_odd=log_odd))
}
list_levels = array(0,dim=100)
sem_disc = glmdisc(x,y,iter=600,m_start=10,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
for (b in 1:100) {
list2env(generate_data(b,1000),env=environment())
sem_disc = glmdisc(x,y,iter=600,m_start=10,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,3]))
}
B
b
for (b in 2:100) {
list2env(generate_data(b,1000),env=environment())
sem_disc = glmdisc(x,y,iter=600,m_start=10,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,3]))
}
library(glmdisc)
d=2
generate_data <- function(k,n) {
set.seed(k)
x = matrix(runif(d*n), nrow = n, ncol = d)
cuts = seq(0,1,length.out= 4)
xd = apply(x,2, function(col) as.numeric(cut(col,cuts)))
theta = t(matrix(c(0,0,0,2,2,2,-2,-2,-2),ncol=3,nrow=3))
log_odd = rowSums(t(sapply(seq_along(xd[,1]), function(row_id) sapply(seq_along(xd[row_id,]),
function(element) theta[xd[row_id,element],element]))))
y = rbinom(n,1,1/(1+exp(-log_odd)))
return(list(x=x,y=y,log_odd=log_odd))
}
list_levels = array(0,dim=100)
list_c1 = array(0,dim=100)
list_c2 = array(0,dim=100)
for (b in 1:1) {
list2env(generate_data(b,1000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(order(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(order(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
summary(factor(list_levels))
list_c1
list_c2
val1
mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
list_c1 = array(0,dim=100)
list_c2 = array(0,dim=100)
list_levels = array(0,dim=100)
for (b in 1:100) {
list2env(generate_data(b,1000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
link[[j]]
recover()
i
j
m
link
j
link[[j]]
best.disc[[2]]
ncol(data_emap)
data_emap
b
for (b in 3:100) {
list2env(generate_data(b,1000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
b
summary(list_c1)
list_c1
list_c2
summary(list_c1[!list_c1 == 0])
summary(list_c2[!list_c2 == 0])
for (b in 34:100) {
list2env(generate_data(b,1000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
b
summary(list_c1[!list_c1 == 0])
summary(list_c2[!list_c2 == 0])
for (b in 94:100) {
list2env(generate_data(b,1000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
b
summary(list_c2[!list_c2 == 0])
list_c2[!list_c2 == 0]
length(list_c2[!list_c2 == 0])
prev = list_c2[!list_c2 == 0]
list_levels = array(0,dim=100)
list_c1 = array(0,dim=100)
list_c2 = array(0,dim=100)
for (b in 1:20) {
list2env(generate_data(b+100,1000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
b
length(prev)
for (b in 12:20) {
list2env(generate_data(b+100,1000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
b
list_c2[!list_c2 == 0]
c(prev,list_c2[!list_c2 == 0])
order(c(prev,list_c2[!list_c2 == 0])[1:100])[c(5,95)]
sort(c(prev,list_c2[!list_c2 == 0])[1:100])[c(5,95)]
sort(c(prev,list_c2[!list_c2 == 0])[1:100])
sort(c(prev,list_c2[!list_c2 == 0])[1:100])[c(5,95)]
length(c(prev,list_c2[!list_c2 == 0]))
sort(c(prev,list_c2[!list_c2 == 0]))[1:100][c(5,95)]
library(glmdisc)
rm(list=ls())
library(glmdisc)
d=2
generate_data <- function(k,n) {
set.seed(k)
x = matrix(runif(d*n), nrow = n, ncol = d)
cuts = seq(0,1,length.out= 4)
xd = apply(x,2, function(col) as.numeric(cut(col,cuts)))
theta = t(matrix(c(0,0,0,2,2,2,-2,-2,-2),ncol=3,nrow=3))
log_odd = rowSums(t(sapply(seq_along(xd[,1]), function(row_id) sapply(seq_along(xd[row_id,]),
function(element) theta[xd[row_id,element],element]))))
y = rbinom(n,1,1/(1+exp(-log_odd)))
return(list(x=x,y=y,log_odd=log_odd))
}
list_levels = array(0,dim=100)
list_c1 = array(0,dim=100)
list_c2 = array(0,dim=100)
for (b in 1:100) {
list2env(generate_data(b,10000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
b
sort(list_c2)[c(5,95)]
list_c2
for (b in 67:100) {
list2env(generate_data(b,10000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
b
list_c2
list_c2[-which(list_c2)==0]
list_c2[-which(list_c2==0)]
prev = list_c2[-which(list_c2==0)]
list_levels = array(0,dim=100)
list_c1 = array(0,dim=100)
list_c2 = array(0,dim=100)
for (b in 1:15) {
list2env(generate_data(b+100,10000),env=environment())
sem_disc = glmdisc(x,y,iter=200,m_start=3,test=FALSE,validation=FALSE,criterion="bic",interact=FALSE)
list_levels[b] = nlevels(factor(sem_disc@disc.data[,1]))
if (list_levels[b]==3) {
val1 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[1],1]
val2 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[2],1]
val3 = sem_disc@cont.data[sem_disc@disc.data[,1] == levels(sem_disc@disc.data[,1])[3],1]
list_c1[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[2:3])
list_c2[b] = mean(sort(c(min(val1),max(val1),min(val2),max(val2),min(val3),max(val3)))[4:5])
}
}
list_c2
sort(c(prev,list_c2))[1:100][c(5,95)]
sort(c(prev,list_c2[-which(list_c2==0)]))[1:100][c(5,95)]
read.csv("~/Desktop/villa.csv")
df = read.csv("~/Desktop/villa.csv")
library(FactoMineR)
pca_villa = PCA(df)
?read.csv
df = read.csv("~/Desktop/villa.csv", row.names = 1)
pca_villa = PCA(df)
plot(pca_villa, choix = 'ind')
plot(pca_villa)
plot(pca_villa, choix = 'var')
?plot.PCA
plot(pca_villa, choix = 'varcor')
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
set.seed(2)
x = matrix(runif(300), nrow = 100, ncol = 3)
cuts = seq(0,1,length.out= 4)
xd = apply(x,2, function(col) as.numeric(cut(col,cuts)))
theta = t(matrix(c(0,0,0,2,2,2,-2,-2,-2),ncol=3,nrow=3))
log_odd = rowSums(t(sapply(seq_along(xd[,1]), function(row_id) sapply(seq_along(xd[row_id,]),
function(element) theta[xd[row_id,element],element]))))
y = rbinom(100,1,1/(1+exp(-log_odd)))
library(tikzDevice)
predictors = x
labels = y
criterion = 'bic'
m_start = 5
iter = 300
prop.table.robust = function(x, margin = NULL) {
tab <- sweep(x, margin, margin.table(x, margin), "/", check.margin = FALSE)
tab[which(is.na(tab))] <- 1/ncol(tab)
tab
}
noms_colonnes = colnames(predictors)
# Cas complets
continu_complete_case = !is.na(predictors)
# Calculating lengths n and d and data types
n = length(labels)
d = length(predictors[1,])
types_data <- sapply(predictors[1,], class)
if (sum(!(types_data %in% c("numeric","factor")))>0) {
stop(simpleError("Unsupported data types. Columns of predictors must be numeric or factor."))
}
# Initializing list of calculated criterion among which to select the best.
criterion_iter=list()
e = emap = array(0,c(n,d))
for (j in which(types_data=="numeric")) {
e[continu_complete_case[,j],j] = emap[continu_complete_case[,j],j] = as.factor(sample(1:m_start,sum(continu_complete_case[,j]),replace = TRUE))
e[!continu_complete_case[,j],j] = emap[!continu_complete_case[,j],j] = m_start+1
}
for (j in which(types_data=="factor")) {
# e[continu_complete_case[,j],j] = emap[continu_complete_case[,j],j] = as.factor(sample(1:nlevels(predictors[,j]),n,replace = TRUE))
# e[!continu_complete_case[,j],j] = emap[!continu_complete_case[,j],j] = nlevels(predictors[,j])+1
e[,j] = emap[,j] = as.factor(sample(1:nlevels(predictors[,j]),n,replace = TRUE))
}
m = rep(m_start,d)
m[which(types_data=="numeric")] = as.vector(apply(e[,which(types_data=="numeric")],2,function(col) nlevels(factor(col))))
m[which(types_data=="factor")] = as.vector(apply(e[,which(types_data=="factor")],2,function(col) nlevels(factor(col))))
names(m) <- paste("X", 1:length(m), sep = "")
lev = apply(e,2,function(col) list(levels(factor(col))))
current_best = 1
best_reglog = 0
best_link = 0
options(
tikzLatexPackages = c(
"\\usepackage{bm}",
"\\usepackage{amsfonts}",
"\\usepackage{tikz}",
"\\usepackage[active,tightpage]{preview}",
"\\PreviewEnvironment{pgfpicture}",
"\\setlength\\PreviewBorder{0pt}"))
# SEM algorithm
for (i in 1:iter){
# if (sum(elementwise.all.equal(m,1))==d) {stop("Early stopping rule: all variables discretized in one value")}
data_e = Filter(function(x)(length(unique(x))>1),data.frame(apply(e,2,factor)))
data_emap = Filter(function(x)(length(unique(x))>1),data.frame(apply(emap,2,factor)))
data = data.frame(e,labels = labels)
data_logit = data.frame(emap,labels = labels)
fmla = stats::as.formula(paste("~",paste(colnames(data_e),collapse = "+")))
fmla_logit = stats::as.formula(paste("~",paste(colnames(data_emap),collapse = "+")))
data = stats::model.matrix(fmla, data = data_e)
data_logit = stats::model.matrix(fmla_logit, data = data_emap)
model_reglog = RcppNumerical::fastLR(data_logit,labels)
logit = RcppNumerical::fastLR(data,labels)
# Calculate current performance and update (if better than previous best) current best model.
criterion_iter[[i]] = 2*model_reglog$loglikelihood-log(n)*length(model_reglog$coefficients)
if (criterion_iter[[i]] >= criterion_iter[[current_best]]) {
best_reglog = model_reglog
best_link = tryCatch(link,error=function(cond) list())
current_best = i
best_formula = fmla_logit
}
# Initialization of link function
link=list()
lev_1 = lev
m = apply(e,2,function(el) nlevels(as.factor(el)))
# Update E^j with j chosen at random
for (j in sample(1:d)) {
# p(e^j | x^j) training
if (length(unique(e[continu_complete_case[,j],j]))>1) {
if (sum(lapply(lapply(1:d,function(j) !lev_1[[j]][[1]] %in% lev[[j]][[1]]),sum)>0)>0) {
e[,which(lapply(lapply(1:d,function(j) !lev_1[[j]][[1]] %in% lev[[j]][[1]]),sum)>0)] = sapply(which(lapply(lapply(1:d,function(j) !lev_1[[j]][[1]] %in% lev[[j]][[1]]),sum)>0), function(col) factor(e[,col],levels = lev_1[[col]][[1]]))
}
# Polytomic or ordered logistic regression
if ((types_data[j]=="numeric")) {
link[[j]] = nnet::multinom(e ~ x, data=data.frame(e=e[continu_complete_case[,j],j],x=predictors[continu_complete_case[,j],j]), start = link[[j]]$coefficients, trace = FALSE, Hess=FALSE, maxit=50)
}
}
# p(y|e^j,e^-j) calculation
if ((m[j])>1) {
y_p = array(0,c(n,(m[j])))
levels_to_sample <- unlist(lev[[j]][[1]])
for (k in 1:length(levels_to_sample)) {
modalites_k = data
if (j>1) {
modalites_k[,((3-j+sum((m[1:(j-1)]))):(1-j+sum((m[1:j]))))] = matrix(0,nrow=n,ncol=m[j]-1)
} else {
modalites_k[,(2:((m[1])))] = matrix(0,nrow=n,ncol=(m[j])-1)
}
if (paste0("X",j,as.numeric(levels_to_sample[k])) %in% colnames(data)) {
modalites_k[,paste0("X",j,as.numeric(levels_to_sample[k]))] = rep(1,n)
}
p = glmdisc::predictlogisticRegression(modalites_k,logit$coefficients)
y_p[,k] <- (labels*p+(1-labels)*(1-p))
}
# p(e^j|reste) calculation
if ((types_data[j]=="numeric")) {
t = predict(link[[j]], newdata = data.frame(x = predictors[continu_complete_case[,j],][,j]),type="probs")
if (is.vector(t)) {
t = cbind(1-t,t)
colnames(t) = c("1","2")
}
if (sum(!continu_complete_case[,j])>0) {
t_bis = matrix(NA,nrow = nrow(predictors), ncol = ncol(t) +1)
t_bis[continu_complete_case[,j],1:ncol(t)] = t
t_bis[continu_complete_case[,j],ncol(t)+1] = 0
t_bis[!continu_complete_case[,j],] = t(matrix(c(rep(0,ncol(t)),1),nrow = ncol(t)+1,ncol=sum(!continu_complete_case[,j])))
colnames(t_bis) = c(colnames(t),m_start+1)
t = t_bis
}
} else {
link[[j]] = table(e[,j],predictors[,j])
t = prop.table.robust(t(sapply(predictors[,j],function(row) link[[j]][,row])),1)
}
# Updating emap^j
emap[,j] <- apply(t,1,function(p) names(which.max(p)))
t <- prop.table.robust(t*y_p,1)
e[,j] <- apply(t,1,function(p) sample(levels_to_sample,1,prob = p,replace = TRUE))
if (nlevels(as.factor(e[,j]))>1) {
if (nlevels(as.factor(e[,j]))==m[j]) {
if (j>1) {
data[,((3-j+sum((m[1:(j-1)]))):(1-j+sum((m[1:j]))))] = stats::model.matrix(stats::as.formula("~e"),data=data.frame("e"=factor(e[,j])))[,-1]
} else {
data[,(2:(m[1]))] = stats::model.matrix(stats::as.formula("~e"),data=data.frame("e"=factor(e[,j])))[,-1]
}
} else {
if (which(!lev[[j]][[1]] %in% levels(as.factor(e[,j])))[1]>1) {
data[,paste0("X",j,lev[[j]][[1]][which(!lev[[j]][[1]] %in% levels(as.factor(e[,j])))])] <- matrix(0,nrow = n, ncol = sum(!lev[[j]][[1]] %in% levels(as.factor(e[,j]))))
data[,paste0("X",j,levels(as.factor(e[,j])))[paste0("X",j,levels(as.factor(e[,j]))) %in% colnames(data)]] <- stats::model.matrix(stats::as.formula("~e[,j]"),data=data.frame(e[,j]))[,-1]
} else {
if (length(which(!lev[[j]][[1]] %in% levels(as.factor(e[,j]))))>1) {
data[,paste0("X",j,lev[[j]][[1]][which(!lev[[j]][[1]] %in% levels(as.factor(e[,j])))[-1]])] <- matrix(0,nrow = n, ncol = sum(!lev[[j]][[1]] %in% levels(as.factor(e[,j]))))
}
reste <- stats::model.matrix(stats::as.formula("~e[,j]"),data=data.frame(e[,j]))[,-1]
data[,paste0("X",j,levels(as.factor(e[,j])))[paste0("X",j,levels(as.factor(e[,j]))) %in% colnames(data)]][,-1] <- reste
if (nlevels(as.factor(e[,j]))==2) {
data[,paste0("X",j,levels(as.factor(e[,j])))[paste0("X",j,levels(as.factor(e[,j]))) %in% colnames(data)]][,1] <- as.numeric(reste==0)
} else {
data[,paste0("X",j,levels(as.factor(e[,j])))[paste0("X",j,levels(as.factor(e[,j]))) %in% colnames(data)]][,1] <- as.numeric(rowSums(reste)==0)
}
}
}
} else {
data[,paste0("X",j,lev[[j]][[1]][which(!lev[[j]][[1]] %in% levels(as.factor(e[,j])))])] <- matrix(0,nrow = n, ncol = sum(!lev[[j]][[1]] %in% levels(as.factor(e[,j]))))
}
} else {
# e^j and emap^j for disappearing features
e[,j] <- emap[,j] <- factor(rep(1,n))
}
tikz(paste0('sem_simulated_data/sem_feature_',j,'_iter_',i,'.tex'), standAlone=FALSE, width = 4, height = 3, fg = "black")
plot(predictors[,j],e[,j], xlab = '$x_j$', ylab = '$\\bm{\\mathfrak{q}}_j$', col = e[,j])
dev.off()
}
lev <- apply(e,2,function(col) list(levels(factor(col))))
message("Iteration ",i," ended with a performance of ",criterion," = ", criterion_iter[[i]])
}
